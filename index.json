[{"categories":["杂文"],"content":"2022年度总结","date":"2022-12-31","objectID":"/2022/","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"虽然我看了多位学长/同学的年度总结感触很深，但是没有打算自己也写一篇，敌不过朝阳再三催促，于是就有了这篇流水账。 2022年我去了很多地方，有了很多之前从未有过的奇特经历，虽然体验起来感觉大多平淡，但是回忆起来还是有趣的。希望我多年以后可以通过这篇文章想起我的大二、大三生活，想起来我20岁的时候竟然做了这么多事，并且摇着头感慨一下年轻真好（笑）。 ","date":"2022-12-31","objectID":"/2022/:0:0","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"这一年过的 ","date":"2022-12-31","objectID":"/2022/:1:0","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"暑假前 由于22年初西安的疫情，封在宿舍，每天写写代码，和室友闲扯，冲去食堂打饭，然后做核酸。本来以为自己没办法回家过年，然而西安突然全域降为低风险区，于是我在当天下午决定立即回家，并在第二天，也就是1月25日凌晨3点出发，在当天中午抵达太原。神奇的是吴亚蒙好像和我有种莫名的默契，在不知道我回到太原的情况下突然联系我，然后我就在刚抵达太原并且补了补觉后和他出去在汾河旁溜了一圈，那么冷的天一路听歌溜到晚上十点。 那天晚上的汾河 这个寒假回家最大的乐趣其实就是见到了很多之前的同学。 俩同学 打球 寒假开学的前一天晚上，又是神奇的吴亚蒙，在不知道我第二天要走的情况下再次联系我，让我和他出去转转。 羞涩蒙蒙 开学之后，期末考试+熬夜刷课+准备面试，两轮面试后拿到了Transwarp数据库内核开发的实习机会，并于5月远程入职，开始远程工作。入职后我开始下班后和室友去健身，并且励志扣篮，虽然现在早已因为各种原因荒废。 之后是六月底酷暑之中的军训，熟悉了很多班里同学。每天根本睡不够，日常闭着眼站军姿。 认真站军姿 到这里，疫情突然又又又来了，一天下午我还在健身房和室友嘿咻，得知西安所有大学当天晚上要封校，然后紧接着就是军训提前结束，立即放假，于是我们有了大约7个小时的时间逃离大学，全西安的大学生好像都开始了逃亡。暑假突然来了，我选择直接去上海线下实习。 咸阳机场旁住了一晚，拍了张照片 ","date":"2022-12-31","objectID":"/2022/:1:1","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"暑假及之后 7月6日抵达上海。第一次一个人在外地住这么久，一间很小并且破烂的屋子。初到上海并没有见识到我印象里的繁华，打开手机搜了下我租住小区的房价才惊呼，这确实是上海！ 刚到住的地方 在上海期间和在上海工作的表姐逛了外滩。 第一次来外滩 闲不住的我又在八月找周末跑去南京，找在南京留守学校的高中同学玩了两天，瞻仰了中山陵，看了长江夜景，参观了南京大屠杀纪念馆和南京博物院，两个男生还是有点浪漫在里面的。 到达南京 南京博物院 长江 中山陵 南京大屠杀纪念馆 实习期间，每天感觉睡不够，中间甚至一整晚未入眠导致第二天请假没去上班。因为实习刚开始杂活比较多，并且自己没什么斗志去学习，陷入了恶性循环，带来了严重的焦虑，导致睡眠质量很差，并且本来高三后已经几乎两年没有起痘、皮肤状态已经恢复到高二水平的我，又开始起痘了… 实习虽说一开始打杂居多，但是mentor待我很好，同事关系融洽，mentor每天都叫我一起吃饭，吃饭成了工作日中最快乐的时光，能和同事从头聊到尾，共同话题非常多。在我离职后，mentor还专门在周末请我吃了顿，算是做了告别，“我们有缘再见”。 公司的工位 九月底的时候，我想有更多时间搞开源项目、看论文，于是提了离职，回到了学校。事与愿违，我还是没有足够的耐心去学习，艰难地用一个多月时间给DuckDB和ClickHouse等项目提交了一些代码，并且看了三四篇论文。给开源项目贡献代码是一个有意思的经历，看到自己的代码能够被国外知名项目接受是非常开心的，并且也是第一次用英语和外国人交流，几十词的英语回复可能会想好几分钟。 这段时间在学校虽然没有很认真学习，但是和室友每日嗨聊，一起看pubg世界赛和世界杯，属实快乐。 之后在十一月底我又开始想找实习了，给自己充实一下简历，也希望能学到一些东西。可是在我拖沓了这么久之后，已经没有几家公司在招人了，室友一直向我推荐的字节ByteHouse组也在之后证明不再招人。我把目光投向了Matrix Origin，我在去年通过一位在这里实习的学长知道了这个创业团队，这位学长在这里成长为大佬并在残酷的23届校招中收割了数个超级大包。这家公司很有意思的是面试前会布置一个小作业，我收到的任务是cpp实现ngram算法，用时四天，最后一天还做上瘾了没吃午饭。第一轮面试把简历从头问到尾，并且出了两道算法题，前面问题答的一般，但是算法题均给出了最优解，过。二面是cto面，给足了压力，cto就一个无情的提问机器，17分钟问出了一小时的量，并且丝毫不与我讨论我给出的答案是否正确，也不给我多留思考时间。有惊无险，面试结束两小时后hr通知我通过了。之后就是hr面，并且最后和公司ceo聊了聊，ceo还和我打听前文提到的学长的秋招去向，并和我无奈感叹，没办法，大厂给钱太多了，我们确实留不住他。 我面试全部通过后被告知公司因为实习生太多了不想再招了，需要再加一轮面试来由另一位领导决定我是否可以入职。但是在12月12日下午又突然和我说不需要加面了，直接给我发offer。得知这个消息时朝阳已经在我身边念叨了一中午的大理大理，于是我俩决定去大理，并计划一周后我直接从云南到上海去实习，这一天属实魔幻。 然后就开启了我称之为年度最佳周，从决定去大理到抵达大理只用了一天半的时间。12月13日晚上11点，辗转昆明后到达大理。 昆明机场 大理站 两人骑电动车花一天时间环洱海一整圈，全程上百公里。 环洱海 环洱海 然后坐客车去丽江，在丽江去了玉龙雪山。神奇的是我到达丽江的时候已经阳了，登上海拔4680的玉龙雪山的我，体温38.8℃。 雪山 高原湖 12月19日，从丽江机场出发，时隔三个月再次到达上海，开启了另一段实习。得益于飞机神奇的航线，人生第一次见到海，就在飞机上。这段实习应该不会再有那么多打杂了，刚入职就接到了不错的开发需求。 平安夜再次来到外滩，这次是一个人。 第二次来外滩 ","date":"2022-12-31","objectID":"/2022/:1:2","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"我的学习和焦虑 早在大一结束时我就对基础软件和底层系统产生了浓厚兴趣，并且决定将来从事基础软件相关工作，之后在几位学长的影响下，在去年年末和今年学习了分布式系统与数据库，刷完了6.824和cmu445两门课程，这期间还因为公开代码仓库收到了麻省理工的Robert教授的邮件，要求我将代码仓库设为private，也算是一个惊喜了。 收到了大神的邮件，虽然是因为不好的事情 4月学习cpp和cmu445的接近一个月的时间是我今年最认真学习的一段时间，整个人是上瘾的状态，甚至不想去吃饭，几乎每天都是凌晨2点多还不舍得睡觉。 在这之后，我再也没有了刷课时的斗志，在之后的大半年时间里进步缓慢，想读的论文一拖再拖，想看文章和项目：收藏=看了，自己对数据库的兴趣也消磨殆尽。这是真正让我苦恼并且带来焦虑的事情，明知自己学识浅薄，但是行动不起来… 尽管如此，我应该保持更多的希望。即使今年秋招难度大增，但是看到多位学长收获了我在大学前根本不敢想的薪资的工作机会，这让我倍受鼓舞。我自己也并非在过去的一年一无所成，只是与自己预期相去甚远。 ","date":"2022-12-31","objectID":"/2022/:2:0","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"希望新的一年里 我可以提升睡眠质量 从容处理压力与焦虑，能平静地专注于手边的问题 我可以重拾斗志，认真工作、看论文、学习计算机基础知识、贡献开源项目。 秋招收获满意的offer 锻炼身体（我还想扣篮呢） 有机会多去不同的地方转转 多拍拍照，发发朋友圈 支线任务：收获爱情 ","date":"2022-12-31","objectID":"/2022/:3:0","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["杂文"],"content":"其他 我都忘了当天是我生日，却突然收到的生日蛋糕，后来赠者被我猜到了，感谢郭同学。 三月养的一只小乌龟，可惜是僵苗，半年后死掉了。 贡献代码后矩阵起源送来的纪念品。 贡献代码后StoneDB送来的纪念品。 上海的天气真好。 ","date":"2022-12-31","objectID":"/2022/:4:0","tags":["年度总结"],"title":"2022年度总结","uri":"/2022/"},{"categories":["数据库"],"content":"CMU-15-445","date":"2022-04-14","objectID":"/cmu445/","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"CMU-15-445 ","date":"2022-04-14","objectID":"/cmu445/:0:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Project 1 ","date":"2022-04-14","objectID":"/cmu445/:1:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"LRUReplacer 理解Pin与Unpin: 参考《数据库系统概念》，当有线程在读取一个 Page 时，这个 Page 是不能被淘汰的，因此需要Pin操作将它移出 LRUReplacer 。同时 Page 类中会有计数器记录有几个线程正在读取它的内容，当计数器降为 0 时，用 Unpin 操作将其添加进 LRUReplacer 。 实现方式是采用双端队列与哈希表，思路与分布式缓存中的相同。 ","date":"2022-04-14","objectID":"/cmu445/:1:1","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"BufferPoolManager 我的刷盘策略: 懒刷盘，只有当一个页面被驱逐或者被上层显式调用刷盘时才进行刷盘。 frame_id和获得页框的方法: frame_id 就是pages_数组的下标，代表一个内存“页框”，用于存放物理页。一开始所有frame_id均在free_list_中，当占用一个 frame_id 时，将它从free_list_取出，并在page_table_建立映射，注意此时并不将其放入replacer_，因为此时上层调用者会使用返回的Page，pin_count_不为零，只有可以进行驱逐的frame_id才会放入replacer_。当后期free_list_为空时，获得一个新页框的方法是从replacer_中驱逐一个页面，得到它对应的页框，此时应注意对驱逐的页面刷盘。 易错点: 1.UnpinPgImp()操作中，page_table_找不到要Unpin的页面时，应当返回 true 。 2.DeletePgImp()中如果成功删除掉一个页，应该 Pin 一下对应的 frame_id 。保证一个 frame_id 只能出现在free_list_或replacer_中的一个地方，当然也有可能均不出现(此时这个 frame_id 是正在被使用的，pin_count_大于零，无法被驱逐)。 ","date":"2022-04-14","objectID":"/cmu445/:1:2","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"ParallelBufferPoolManager 用std::vector\u003cBufferPoolManagerInstance*\u003e bpms_记录管理的 BufferPoolManagerInstance ，用size_t next_instance_记录下一个页面应当分配在哪一个 BufferPoolManagerInstance 。注意只有NewPgImp()操作需要加锁，这个 ParallelBufferPoolManager 就是为了提高并发度的。 ","date":"2022-04-14","objectID":"/cmu445/:1:3","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"得分情况与优化 因 BufferPoolManager 中的易错点一开始只有 42 分，修改完成后达到满分，Time 13.01 ，排名 212 。后进行优化，将双向队列中的智能指针改为原始指针，并在FlushPgImp()和FlushAllPgsImp()中将 Page 的is_dirty_设为 false ，避免重复刷盘。优化后 Time 9.63 ，排名 84 。 ","date":"2022-04-14","objectID":"/cmu445/:1:4","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Project 2 ","date":"2022-04-14","objectID":"/cmu445/:2:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"参考资料 Extendible Hash Table Extendible Hashing (Dynamic approach to DBMS) 一定要仔细看Project提供的已有代码！ ","date":"2022-04-14","objectID":"/cmu445/:2:1","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"组织结构说明 一个Page的大小在config.h中给出，为 4096 byte，那么如何确定BUCKET_ARRAY_SIZE呢？BUCKET_ARRAY_SIZE是一页中可以存放的键值对数，每一个键值对还需要两 bit 的 readable 和 occupied 标志，所以可以通过算式PAGE_SIZE/(sizeof (MappingType) + 0.25)分子分母同乘4得到hash_table_page_defs.h中的#define BUCKET_ARRAY_SIZE (4 * PAGE_SIZE / (4 * sizeof(MappingType) + 1))。 可以注意到Page类中data_的大小就是一个 PAGE_SIZE ，同时也注意到HashTableBucketPage没有构造函数和析构函数并且存放数据的array_长度为零，那如何产生一个HashTableBucketPage对象？在课程官网有提到reinterpret_cast，分配一个HashTableBucketPage对象时调用auto bucket_page = reinterpret_cast\u003cHashTableBucketPage\u003cint, int, IntComparator\u003e *\u003e(bpm-\u003eNewPage(\u0026bucket_page_id, nullptr)-\u003eGetData());，这时会按照Page类中GetData()返回的大小为 PAGE_SIZE 的数据分配内存，然后被HashTableBucketPage指针指向，HashTableBucketPage指针指向的内存大小就是一个 PAGE_SIZE ，因为array_变量在类的尾部声明，就可以使用array_来访问页中数据，即使array_的长度被声明为 0 。HashTableDirectoryPage的内存分配同理。 页中的键值对是以std::pair\u003cKeyType, ValueType\u003e的形式存放的，KeyType是一个模板类，内部是一个长度为KeySize的定长 char 数组。ValueType是RID(Record ID)类，存放长度为 32 bit 的slot_num_与 32 bit 的page_id_，其实就是对应数据页的 id 和该 Record 在数据页内的偏移，和 Project 3 有关，现在可以不管。 当一个键值对加入 bucket 后，如果要删除它，是将它对应的 readable 标志置为 0 ，意味着此时这个位置是一个 tombstone 。 DIRECTORY_ARRAY_SIZE为 512 ，所以GlobalDepth最大为 9 。 HashTableDirectoryPage与ExtendibleHashTable共用一把table_latch_。 截止当前 Project ，可见的项目结构如图： ","date":"2022-04-14","objectID":"/cmu445/:2:2","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"易错点 1.千万记住 Unpin 不再使用的 Page ，包括HashTableDirectoryPage。 2.课程要求使用 least-significant bits 作为 index ，这和很多参考资料上画的是相反的，要注意。 3.我给Insert()加的是读锁，多个线程同时执行Insert()，全部 insert 到一个满的桶上都会到SplitInsert()扩容，为了避免重复扩容，SplitInsert()先检查是否可以插入成功并且不扩容。至于为什么Insert()加读锁，是因为大部分insert操作不改变 HashTable 的全局状态，加读锁性能明显更好。Merge()同理。 4.桶分裂时当前桶可能存在于bucket_page_ids_中的多个位置，注意全部设成正确的新值。 5.对目录进行 Shrink 之后应该再对所有空桶进行检查是否能合并，因为 Shrink 之后刚刚合并的桶的 SplitBucket 发生了改变，可能继续与空桶合并。 ","date":"2022-04-14","objectID":"/cmu445/:2:3","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"神奇的位运算 HashTableDirectoryPage和HashTableBucketPage中有很多函数用到了几个比较妙的位运算，并且这几个函数对于ExtendibleHashTable中的几个骚操作很有帮助。根据参考材料和课程提供的注释使用这些函数即可。下面是其中几个比较有意思的实现。 uint32_t HashTableDirectoryPage::GetSplitImageIndex(uint32_t bucket_idx) { return bucket_idx ^ (1 \u003c\u003c (local_depths_[bucket_idx] - 1)); } template \u003ctypename KeyType, typename ValueType, typename KeyComparator\u003e void HASH_TABLE_BUCKET_TYPE::RemoveAt(uint32_t bucket_idx) { readable_[bucket_idx \u003e\u003e 3] \u0026= ~(1 \u003c\u003c (bucket_idx \u0026 7)); } template \u003ctypename KeyType, typename ValueType, typename KeyComparator\u003e bool HASH_TABLE_BUCKET_TYPE::IsOccupied(uint32_t bucket_idx) const { return occupied_[bucket_idx \u003e\u003e 3] \u0026 (1 \u003c\u003c (bucket_idx \u0026 7)); } template \u003ctypename KeyType, typename ValueType, typename KeyComparator\u003e void HASH_TABLE_BUCKET_TYPE::SetOccupied(uint32_t bucket_idx) { occupied_[bucket_idx \u003e\u003e 3] |= 1 \u003c\u003c (bucket_idx \u0026 7); } template \u003ctypename KeyType, typename ValueType, typename KeyComparator\u003e bool HASH_TABLE_BUCKET_TYPE::IsReadable(uint32_t bucket_idx) const { return readable_[bucket_idx \u003e\u003e 3] \u0026 (1 \u003c\u003c (bucket_idx \u0026 7)); } template \u003ctypename KeyType, typename ValueType, typename KeyComparator\u003e void HASH_TABLE_BUCKET_TYPE::SetReadable(uint32_t bucket_idx) { readable_[bucket_idx \u003e\u003e 3] |= 1 \u003c\u003c (bucket_idx \u0026 7); } ","date":"2022-04-14","objectID":"/cmu445/:2:4","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"得分情况 一共两次有效提交，第一次因为没有注意到易错点 5 只有 75 分，改正后达到满分，Time 32.96 ，排名 38 ，还算是比较靠前的，有时间再优化一下，很多逻辑都还可以简化，但是重构比较麻烦。 ","date":"2022-04-14","objectID":"/cmu445/:2:5","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Project 3 ","date":"2022-04-14","objectID":"/cmu445/:3:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"参考资料 课程PPT重点看 Processing Models 和 Expression Evaluation 。 CMU15-445 数据库实验全满分通过笔记 Hash Join ","date":"2022-04-14","objectID":"/cmu445/:3:1","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"组织结构说明 执行相关: ExecutionEngine是一个执行计划被执行的地方，它接收上层的执行计划并执行后返回结果集，执行时会调用ExecuteFactory的静态方法CreateExecutor(ExecutorContext *, const AbstractPlanNode *)新建一个std::unique_ptr\u003cAbstractExecutor\u003e用以进行执行操作。它的成员变量如下，其中的Catalog *catalog_是用于进行 table creation, table lookup, index creation, and index lookup 的。([[maybe_unused]]是一个 C++17 新特性，详见Attributes) private: /** The buffer pool manager used during query execution */ [[maybe_unused]] BufferPoolManager *bpm_; /** The transaction manager used during query execution */ [[maybe_unused]] TransactionManager *txn_mgr_; /** The catalog used during query execution */ [[maybe_unused]] Catalog *catalog_; ExecutorContext保存了一个语句的执行过程中可能用到的上下文信息,ExecuteFactory创建 Executor 的时候会将ExecutorContext传递给Executor。成员变量如下。 private: /** The transaction context associated with this executor context */ Transaction *transaction_; /** The datbase catalog associated with this executor context */ Catalog *catalog_; /** The buffer pool manager associated with this executor context */ BufferPoolManager *bpm_; /** The transaction manager associated with this executor context */ TransactionManager *txn_mgr_; /** The lock manager associated with this executor context */ LockManager *lock_mgr_; 每个执行都会有一个执行计划类，ExecuteFactory创建 Executor 的时候也会把对应的执行计划类传递给Executor。 索引和表相关: Tuple可以看作是一个数据行，有着唯一的 RID(Record ID) ，即 Project 2 中哈希表的ValueType，RID类，存放长度为 32 bit 的slot_num_与 32 bit 的page_id_，其实就是对应TablePage的 id 和该 Record 在数据页内的偏移。哈希表中查到 RID 之后就可以根据 RID 获取对应的数据行。 Schema schema_保存了一张表中的列信息，主要包含std::vector\u003cColumn\u003e cols，Column即记录一个列的信息，包括这一列的名字、数据类型和在Tuple中的偏移量，并且保存了创建一个列的表达式const AbstractExpression *expr_。 TableInfo保存一张表的信息，其中主要包含Schema schema_、std::string name、std::unique_ptr\u003cTableHeap\u003e table_。TableHeap代表了一个存在于磁盘的表，用于对表进行真正的修改操作。TablePage是表的存储单元，保存了Tuple，TableHeap中有TablePage的双向链表，表内容修改操作发生于TablePage。 TablePage中的注释很好地说明了数据是如何保存在表中的。 /** * Slotted page format: * --------------------------------------------------------- * | HEADER | ... FREE SPACE ... | ... INSERTED TUPLES ... | * --------------------------------------------------------- * ^ * free space pointer * * Header format (size in bytes): * ---------------------------------------------------------------------------- * | PageId (4)| LSN (4)| PrevPageId (4)| NextPageId (4)| FreeSpacePointer(4) | * ---------------------------------------------------------------------------- * ---------------------------------------------------------------- * | TupleCount (4) | Tuple_1 offset (4) | Tuple_1 size (4) | ... | * ---------------------------------------------------------------- * */ IndexInfo记录了一个索引的信息，成员如下，其中std::unique_ptr\u003cIndex\u003e index_使用的就是 Project 2 实现的 ExtendibleHashTable 。 /** The schema for the index key */ Schema key_schema_; /** The name of the index */ std::string name_; /** An owning pointer to the index */ std::unique_ptr\u003cIndex\u003e index_; /** The unique OID for the index */ index_oid_t index_oid_; /** The name of the table on which the index is created */ std::string table_name_; /** The size of the index key, in bytes */ const size_t key_size_; Catalog使用TableInfo与IndexInfo两个结构来对表和索引进行操作。 ","date":"2022-04-14","objectID":"/cmu445/:3:2","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Nested Loop Join Nested Loop Join 写起来感觉怪怪的，贴一下我的代码吧，不知道逻辑对不对，测试是过了。 void NestedLoopJoinExecutor::Init() { left_executor_-\u003eInit(); right_executor_-\u003eInit(); first_ = true; } bool NestedLoopJoinExecutor::Next(Tuple *tuple, RID *rid) { if (first_ \u0026\u0026 !left_executor_-\u003eNext(\u0026left_tuple_, \u0026left_rid_)) { return false; } first_ = false; Tuple right_tuple; RID right_rid; while (true) { while (right_executor_-\u003eNext(\u0026right_tuple, \u0026right_rid)) { if (plan_-\u003ePredicate() == nullptr || plan_-\u003ePredicate() -\u003eEvaluateJoin(\u0026left_tuple_, left_executor_-\u003eGetOutputSchema(), \u0026right_tuple, right_executor_-\u003eGetOutputSchema()) .GetAs\u003cbool\u003e()) { std::vector\u003cValue\u003e output; for (const auto \u0026col : GetOutputSchema()-\u003eGetColumns()) { output.push_back(col.GetExpr()-\u003eEvaluateJoin(\u0026left_tuple_, left_executor_-\u003eGetOutputSchema(), \u0026right_tuple, right_executor_-\u003eGetOutputSchema())); } *tuple = Tuple(output, GetOutputSchema()); return true; } } if (!left_executor_-\u003eNext(\u0026left_tuple_, \u0026left_rid_)) { break; } right_executor_-\u003eInit(); } return false; } ","date":"2022-04-14","objectID":"/cmu445/:3:3","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Hash Join 这个自己按照我的 Nested Loop Join 的方法写出来线上测试过不了，后来按照CMU15-445 数据库实验全满分通过笔记的修改，代码如下。 void HashJoinExecutor::Init() { left_child_-\u003eInit(); right_child_-\u003eInit(); // 初始化哈希表阶段 Tuple left_tuple; RID left_rid; while (left_child_-\u003eNext(\u0026left_tuple, \u0026left_rid)) { HashJoinKey hash_key{plan_-\u003eLeftJoinKeyExpression()-\u003eEvaluate(\u0026left_tuple, left_child_-\u003eGetOutputSchema())}; if (map_.count(hash_key) != 0) { map_[hash_key].emplace_back(left_tuple); } else { map_[hash_key] = std::vector{left_tuple}; } } left_index_ = -1; } bool HashJoinExecutor::Next(Tuple *tuple, RID *rid) { // 探测阶段 HashJoinKey cur_key; if (left_index_ != -1) { cur_key.key_ = plan_-\u003eRightJoinKeyExpression()-\u003eEvaluate(\u0026right_tuple_, right_child_-\u003eGetOutputSchema()); } if (left_index_ == -1 // 判断是否第一次执行Next() || map_.find(cur_key) == map_.end() // 判断当前是否已经指向一个能join的右表tuple || left_index_ == static_cast\u003cint\u003e(map_[cur_key].size()) // 判断这个能join的右表tuple是否还能跟左表tuple相结合 ) { while (true) { if (right_child_-\u003eNext(\u0026right_tuple_, \u0026right_rid_)) { cur_key.key_ = plan_-\u003eRightJoinKeyExpression()-\u003eEvaluate(\u0026right_tuple_, right_child_-\u003eGetOutputSchema()); if (map_.find(cur_key) != map_.end()) { left_index_ = 0; break; } } else { return false; } } } auto cur_vector = map_.find(cur_key)-\u003esecond; auto cur_left_tuple = cur_vector[left_index_]; std::vector\u003cValue\u003e output; for (const auto \u0026col : GetOutputSchema()-\u003eGetColumns()) { output.push_back(col.GetExpr()-\u003eEvaluateJoin(\u0026cur_left_tuple, left_child_-\u003eGetOutputSchema(), \u0026right_tuple_, right_child_-\u003eGetOutputSchema())); } *tuple = Tuple(output, GetOutputSchema()); ++left_index_; return true; } ","date":"2022-04-14","objectID":"/cmu445/:3:4","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"得分情况 这个 Project 的线上测试因为测试框架的更新导致编译失败，详见Issue #227。向提交的压缩包中加入 /src/include/storage/page/tmp_tuple_page.h 后即可编译成功。第一次提交因为 Hash Join 超时得到 330 分，修改后达到满分，Time 3.87 ，排名 30 。 ","date":"2022-04-14","objectID":"/cmu445/:3:5","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"Project 4 ","date":"2022-04-14","objectID":"/cmu445/:4:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"参考资料 《数据库系统概念》 CMU15-445 数据库实验全满分通过笔记 2021 CMU 15-445 实验笔记 ","date":"2022-04-14","objectID":"/cmu445/:4:1","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"三种隔离级别 READ_UNCOMMITED: 读取不需要获得共享锁，写入需要获得排他锁，用完直接放锁。 READ_COMMITTED: 要解决脏读的问题，解决方案就是读时上读锁，读完解读锁；写时上写锁，但等到commit时才解写锁；读时上读锁，读完解读锁。这样，永远不会读到未commit的数据，因为上面有写锁。 REPEATABLE_READ: 读取和写入均需要锁，需要遵守强两阶段锁规则。 ","date":"2022-04-14","objectID":"/cmu445/:4:2","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"事务状态 注意: Any failed lock operation should lead to an ABORTED transaction state (implicit abort) and throw an exception. The transaction manager would further catch this exception and rollback write operations executed by the transaction. * Transaction states for 2PL: * _________________________ * | v * GROWING -\u003e SHRINKING -\u003e COMMITTED ABORTED * |__________|________________________^ * * Transaction states for Non-2PL: * __________ * | v * GROWING -\u003e COMMITTED ABORTED * |_________________________^ * ","date":"2022-04-14","objectID":"/cmu445/:4:3","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"加锁解锁逻辑 按照《数据库系统概念》18.1.4 的描述和2021 CMU 15-445 实验笔记的思路实现即可。下面是课程官网的提示。 LockShared(Transaction, RID): Transaction txn tries to take a shared lock on record id rid. This should be blocked on waiting and should return true when granted. Return false if transaction is rolled back (aborts). LockExclusive(Transaction, RID): Transaction txn tries to take an exclusive lock on record id rid. This should be blocked on waiting and should return true when granted. Return false if transaction is rolled back (aborts). LockUpgrade(Transaction, RID): Transaction txn tries to upgrade a shared to exclusive lock on record id rid. This should be blocked on waiting and should return true when granted. Return false if transaction is rolled back (aborts). This should also abort the transaction and return false if another transaction is already waiting to upgrade their lock. Unlock(Transaction, RID): Unlock the record identified by the given record id that is held by the transaction. ","date":"2022-04-14","objectID":"/cmu445/:4:4","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"得分情况和疑惑 这个 Project 真写麻了，是四个 Project 里最痛苦的，一开始只有 55 分，和死锁预防的有关的测试全部超时，后来在CMU15-445 数据库实验全满分通过笔记看到“如果老事务想上锁，队列中如果有只是在等待并没有获得锁的新事务请求，也要abort它。如果老事务请求继续等待，测试就会超时”，但是这个和《数据库系统概念》讲的又不一样了。虽然最后达到了满分，但是很多实现和教材的有冲突并且我的很多代码逻辑并不完善。Project 4 无排名。 ","date":"2022-04-14","objectID":"/cmu445/:4:5","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["数据库"],"content":"总结 简单了解C++加上做完 CMU 15-445 共计 13 天，对数据库底层原理加深了理解，也知道了《数据库系统概念》这一本很好的教材，还需要仔细看看。共计 44 次提交，感谢连续十多天熬夜 debug 的自己。 ","date":"2022-04-14","objectID":"/cmu445/:5:0","tags":["CMU-15-445"],"title":"CMU-15-445","uri":"/cmu445/"},{"categories":["OS"],"content":"虚拟文件系统","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"虚拟文件系统的作用 虚拟文件系统（Virtual Filesystem）也可以称为虚拟文件系统转换（Virtual Filesystem Switch，VFS），是一个内核软件层，用来处理与Unix标准文件系统相关的所有系统调用。通过虚拟文件系统，Linux可以支持多种不同类型的文件系统。对用户调用的每个读、写或其它函数，内核都会通过虚拟文件系统将它们转化成实际文件系统所支持的函数。 虚拟文件系统 例如，当用户输入以下shell命令：$ cp /floppy/TEST /temp/test。其中 /floppy 是MS-DOS磁盘的一个安装点，而 /temp 是一个标准的第二扩展文件系统（Second Extended Filesystem，Ext2）的目录。此时 cp 程序不需要知道 /floppy/TEST 和 /temp/test 分别是什么文件系统类型，它直接与VFS交互便能实现它的功能。 VFS支持的文件系统主要有以下三种： 1.磁盘文件系统 磁盘文件系统管理在本地磁盘分区中可用的存储空间和其他可以起到磁盘作用的设备（比如一个USB闪存）。实际上，大多数文件系统都由此演变而来。比如，一些众所周知的文件系统，包括Ext2/3、Reiserfs、FAT和iso9660。所有这些文件系统都使用面向块的介质，必须解决以下问题：如何将文件内容和结构信息存储在目录层次结构上。 2.网络文件系统 这种文件系统允许访问另一台计算机上的数据，该计算机通过网络连接到本地计算机。在这种情况下，数据实际上存储在一个不同系统的硬件设备上。这意味着内核无需关注文件存取、数据组织和硬件通信的细节，这些由远程计算机的内核处理。对此类文件系统中文件的操作都通过网络连接进行。在进程向文件写数据时，数据使用特定的协议（由具体的网络文件系统决定）发送到远程计算机。接下来远程计算机负责存储传输的数据并通知发送者数据已经到达。尽管如此，即使在内核处理网络文件系统时，仍然需要文件长度、文件在目录层次中的位置以及文件的其他重要信息。它必须也提供函数，使得用户进程能够执行通常的文件相关操作，如打开、读、删除等。由于VFS抽象层的存在，用户空间进程不会看到本地文件系统与网络文件系统之间的区别。 3.特殊文件系统 最常见的特殊文件系统包括用于进程间通信的pipefs（管道）、sockfs（套接字）、mqueue（POSIX消息队列）。 在Linux系统中，根目录包含在根文件系统中，这个根文件系统通常就是Ext2或Ext3，其他的文件系统都可以被安装在根文件系统的子目录中。 除了为所有文件系统实现一个通用的接口之外，VFS还负责控制磁盘高速缓存，例如目录项高速缓存与索引节点高速缓存、页高速缓存。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"通用文件模型 VFS所隐含的主要思想在于引入了一个通用文件模型，这个文件模型能够表示所有支持的文件系统，囊括了任何文件系统常用的功能集，这使得Linux可以支持差异很大的各种文件系统。要支持一个具体文件系统，内核会将其物理组织结构转换为虚拟文件系统的通用文件模型。 通用文件模型包含一系列对象（没错就是面向对象的设计思路），其中定义了数据结构和操作数据结构的方法，这些方法其实就是一些函数指针，指向了具体文件系统的实现函数。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"VFS的数据结构 通用文件模型由下列对象组成： 1.超级块对象(Superblock Object) 超级块对象存放已安装文件系统的相关信息。 2.索引节点对象(Inode Object) 索引节点对象存放具体文件的一般信息，每个索引节点都有一个索引节点号，这个节点号唯一地标识一个文件。 3.文件对象(File Object) 文件对象存放打开的文件与进程进行交互的有关信息，这些信息仅仅在进程访问文件时才存在于内核中。 4.目录项对象(Dentry Object) 一个目录项是一个路径的组成部分。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"超级块对象 超级块对象由super_block结构表示，定义在文件\u003clinux/fs.h\u003e中，其中包含的主要字段有如下表。 类型 字段 说明 struct list_head s_list 指向超级块链表的指针 unsigned long s_blocksize 以字节为单位的块大小 struct file_system_type * s_type 文件系统类型 struct super_operations * s_op 超级块方法 int s_count 引用计数器 struct list_head s_inodes 所有索引节点链表 struct list_head s_files 文件对象链表 void * s_fs_info 指向特定文件系统的超级块信息的指针 struct semaphore s_lock 超级块信号量 超级块对象中最重要的字段就是s_op，它指向超级块的操作函数表。超级块操作函数表由super_operations结构体表示，定义在\u003clinux/fs.h\u003e中。该结构体的每一项都是一个指向超级块操作函数的指针，超级块操作函数执行文件系统和索引节点的底层操作。当文件系统需要对其超级块进行操作时，首先要在超级块对象中寻找需要的操作方法。常见的超级块操作函数如下表。 操作函数 说明 struct inode *alloc_inode(stuct super_block *sb) 在给定的超级块下创建和初始化一个新的索引节点对象 void destroy_inode(struct inode *inode) 释放给定的索引节点 void delete_inode(struct inode *inode) 从磁盘上删除给定的索引节点 void write_inode(struct inode *inode, int wait) 用于将给定索引节点写入磁盘 一部分超级块操作函数是可选的，文件系统可以将不需要的函数指针设为NULL。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:1","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"索引节点对象 索引节点对象包含了内核在操作文件或目录时的全部信息。对于Unix风格的文件系统来说，这些信息可以从磁盘索引节点直接读入，如果一个文件系统没有索引节点，那么需要从磁盘中提取这些信息。无论采用哪种方式，索引节点对象必须在内存中创建，以便于文件系统使用。 索引节点对象由inode结构体表示，定义在文件\u003clinux/fs.h\u003e中，主要字段如下表。 类型 字段 说明 struct hlist_node i_hash 用于散列表的指针 struct list_head i_list 索引节点链表 struct list_head i_sb_list 超级块链表 struct list_head i_dentry 目录项链表 unsigned long i_ino 节点号 atomic_t i_count 引用计数 unsigned int i_nlink 硬链接计数 loff_t i_size 以字节为单位的文件大小 umode_t i_mode 访问权限 struct file_operations * i_op 索引节点操作表 每个索引节点总是出现在以下三个双向循环链表中：未使用的索引节点链表、正在使用的索引节点链表、脏索引节点链表。所有情况下，指向相邻元素的指针存放在i_list字段中。此外，所有索引节点对象也包含在超级块对象的s_inodes字段中，索引节点对象的i_sb_list字段存放了指向链表相邻元素的指针。 索引节点对象还存放在一个成为inode_hashtable的散列表中。散列表加快了对索引节点的搜索，前提是内核知道了索引节点号及文件所在文件系统对应的超级块对象地址。该散列表采用拉链法解决冲突，冲突链表的前后相邻元素指针由i_hash字段保存。 常见的索引节点操作函数见下表。 操作函数 说明 int link(struct dentry *old_dentry, struct inode *dir, struct dentry *dentry) 该函数被系统调用link()调用，用来创建硬链接,硬链接名称由dentry参数指定，连接对象是dir目录中old_dentry目录项所代表的文件 int unlink(struct inode *dir, struct dentry *dentry) 该函数被系统调用unlink()调用，从目录dir中删除由目录项dentry指定的索引节点对象（硬链接计数减一） int mkdir(sturct inode *dir, struct dentry *dentry, int mode) 该函数被系统调用mkdir()调用,创建一个新目录 int rmdir(sturct inode *dir, struct dentry *dentry) 该函数被系统调用rmdir()调用,删除dir目录中dentry目录项代表的文件 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:2","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"目录项对象 VFS把目录当作文件对待，所以在路径 /bin/vi 中，bin和vi都属于文件，路径中的每个部分都对应有一个索引节点对象表示。路径名查找需要解析路径中的每一个组成部分，不但要确保它有效，还需要进一步寻找路径中的下一个部分。为了方便查找操作，VFS引入目录项的概念。每一个dentry代表路径中的一个特定部分。对于上一个例子来说，/、bin和vi都属于目录项对象，前两个是目录，最后一个是普通文件。 目录项对象由dentry结构体表示，定义在文件\u003clinux/dcache.h\u003e中，主要的字段见下表。 类型 字段 说明 struct list_head d_subdirs 子目录链表 struct dentry * d_parent 父目录项 struct dentry_operations * d_op 目录项操作函数表 struct hlist_node d_hash 散列表 如果遍历路径名中的所有元素并将它们逐个解析为目录项对象，还要到达最深层目录，这是一个很费时的工作，所以内核将目录项对象缓存在目录项缓存中。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:3","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"文件对象 文件对象是已打开的文件在内存中的表示。该对象由open()系统调用创建，由close()系统调用撤销。因为一个文件可以被多个进程打开，所以一个文件可能对应多个文件对象。 文件对象由file结构体表示，定义在\u003clinux/fs.h\u003e中，主要的字段如下。 类型 字段 说明 struct file_operations * f_op 文件操作函数表 mode_t f_mode 访问模式 loff_t f_pos 文件当前偏移量 struct file_ra_state f_ra 预读状态 struct address_space * f_mapping 页缓存映射 文件对象的操作函数是块I/O系统调用的基础，常见的函数如下。 操作函数 说明 ssize_t read(struct file *file, char *buf, size_t count, loff_t *offset) 从给定文件的offset偏移处读取count字节数据到buf中，系统调用read()调用它 ssize_t write(struct file *file, char *buf, size_t count, loff_t *offset) 从buf中取出count字节数据，写入指定文件的offset偏移处，系统调用write()调用它 int lock(struct file *file, int cmd, struct file_lock *lock) 给指定文件上锁 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:4","tags":["Linux内核"],"title":"虚拟文件系统","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["OS"],"content":"Linux块设备I/O","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":" 在我的一篇博客 操作系统概述 中我画了一张关于Linux的块设备I/O分层的示意图，就是下面这张图。这里再写篇整理一下这张图涉及到的知识点，尽量避免陷入源码细节，做到先有宏观认知，再了解各个分层的功能与简单原理即可。 Linux块IO分层 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:0:0","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"块设备 系统中能够随机（不需要按顺序）访问固定大小数据片的硬件设备叫做块设备，这些固定大小的数据片就叫做块。最常见的块设备就是硬盘了。另一种常见的设备类型是字符设备。字符设备按照字符流的方式被有序访问，像键盘就是最常见的字符设备。 对于这两种设备，最重要的区别就是“是否可以随机访问”。举个例子，键盘这种设备提供的就是一个数据流，当我们输入“wolf”这个字符串时，键盘驱动程序会按照和输入完全相同的顺序返回这个由四个字符组成的数据流，对键盘的读操作会得到这个数据流，首先从数据流中读取字符“w”,之后时“o”，再接着就是“l”和“f”。当没有人敲键盘时，数据流就是空的。硬盘等块设备就明显不同，我们可以读取硬盘上的任意块的内容，它们的位置不需要连续，而且没有时间上的绝对顺序要求，可以认为硬盘时被随机访问，因此它是一个块设备。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:1:0","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"块设备I/O流程 1.块设备I/O的起点是虚拟文件系统（VFS），用户会通过一个系统调用发起一个块I/O，比如read()调用，并将文件描述符和文件内的偏移量传递给系统调用。虚拟文件系统位于块设备处理体系的最上层，它提供了一个通用的文件模型和文件系统模型，Linux支持的所有文件系统均采用了该模型，可以理解为虚拟文件系统是磁盘文件系统的一层封装，屏蔽了不同文件系统的区别，提供了统一的函数调用来供用户使用。 2.VFS会确认请求的数据是否已经被缓存到内存，内核会将大多数最近从块设备读出或写入的数据保存到内存中，这里涉及到的是磁盘高速缓存机制。 3.映射层(Mapping Layer)包含了磁盘文件系统，如果请求的数据没有被缓存，那么就需要映射层来帮助确定数据的物理位置。映射层主要执行下面两个步骤： （1）内核确定该文件所在文件系统的块大小，并计算出所请求数据的长度。本质上，文件被拆分成许多块，因此内核会确定请求数据所在的块号。 （2）接下来，映射层调用一个具体文件系统的函数，它访问文件的磁盘节点，然后根据块号确定数据在磁盘上的位置。 4.这时候内核可以开始对块设备发出请求了。内核会利用通用块层(Generic Block Layer)启动I/O操作来传送所请求的数据。一般而言，每个I/O操作只针对磁盘上一组连续的块。由于请求的数据不一定位于相邻的块中，所以通用块层可能会启动多次I/O操作。每个I/O操作是由一个“块I/O”（简称“bio”）结构描述，它收集底层组件需要的所有信息以发出一次I/O请求。 5.通用块层下面的I/O调度程序层会根据特定的调度算法对通用块层发起的I/O请求进行归类和整理，以充分利用磁盘的物理特性来提高I/O效率。简单来讲，I/O调度程序层会把物理介质上相邻的请求聚集在一起，方便磁盘一次性读出。 6.最后，块设备驱动程序向磁盘控制器的硬件接口发送指令，从而实际进行数据传送。当数据传送完成，磁盘控制器就会发出一个中断来通知块设备驱动程序。大多数情况下，磁盘控制器会采用直接内存访问即DMA的方式进行数据传送，简单来讲，DMA就是内存与硬件设备不通过CPU流转数据的直接数据传输。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:2:0","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"管理磁盘数据 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:3:0","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"扇区 磁盘的每次数据传输都基于一组成为扇区的相邻字节，扇区是数据传输的基本单元，不允许传输少于一个扇区的数据，但是可以同时传送几个相邻的扇区。在Linux系统中，扇区大小按惯例都设为512字节。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:3:1","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"块 扇区是硬件设备传送数据的基本单位，而块是VFS和文件系统传送数据的基本单位。一个块可以对应磁盘上一个或多个相邻的扇区。在Linux系统中，块的大小必须是2的幂，而且不能超过一个内存页框。此外，它必须是一个扇区大小的整数倍。块的大小不是唯一的，创建一个磁盘文件系统时，用户可以选择合适的块大小。 每个块都会有自己的缓冲区，当内核从磁盘读出一个块时，就会用读出的块数据填充它对应的缓冲区，同样，在内核向磁盘写入一个块时，也会用写入的数据填充或更新缓冲区。 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:3:2","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["OS"],"content":"段 段是块设备驱动程序能够处理的数据存储单元，一个段就是一个内存页或者内存页中的一部分。 管理磁盘数据 ","date":"2022-01-02","objectID":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/:3:3","tags":["Linux内核"],"title":"Linux块设备I/O","uri":"/linux%E5%9D%97%E8%AE%BE%E5%A4%87io/"},{"categories":["分布式系统"],"content":"分布式缓存","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"概述 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:1:0","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"基本信息 项目地址：https://github.com/taofengliu/cache 这是一个纯内存的缓存玩具工具，节点用来存储具体数据，Router用来接受客户请求并路由到对应节点去查询数据。节点内部用LRU算法来管理数据，Router通过一致性哈希算法管理各个节点。Router启动时会对节点进行简单的测试，确认节点地址正确。Router有感知节点宕机的功能，当查询或设值的节点已经无法使用，Router会删除该节点。在设值时会自动反复重新尝试设值，若所有节点均失效，则Router关闭。 项目的设计灵感来源于《数据密集型应用系统设计》第203页的方案2。 项目结构 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:1:1","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"启动方法 启动一个节点： run go run_nodeserver.go -端口号 -LRU容量(单位：字节) 启动一个Router： run go run_router.go 多个节点地址（以空格分隔） -端口号 -每个真实节点对应的虚拟节点数 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:1:2","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"HTTP API GET {Router地址}/cache/{key值} 来进行查询 POST {Router地址}/cache/{key值} 来进行设值，值通过http body发送 DELETE {Router地址}/cache/{key值} 来进行删值 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:1:3","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"LRU算法 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:2:0","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"双向队列 双向队列就是真正存储每个LRU元素的地方，它有长度限制，如果达到长度上限，那么再添加元素时队列末端的元素就会被挤出队列，每当插入或查询一个元素，它总会被放到队首。 首先定义队列节点。 // Element 队列节点，包含Data用来存储数据 type Element struct { Key string Value Data Pre *Element Next *Element } 再来定义一个双向队列，它包含一个头节点和尾节点。 // LinkedList 一个双向队列 type LinkedList struct { Head *Element Tail *Element } //初始化方法，空的双向队列首尾节点相连 func New() *LinkedList { head := Element{ Key: \"Head\", Value: Data{}, } tail := Element{ Key: \"Tail\", Value: Data{}, } head.Next = \u0026tail tail.Pre = \u0026head list := LinkedList{ Head: \u0026head, Tail: \u0026tail, } return \u0026list } 为了方便删除元素、将元素添加到队首，再来写两个方法。这时候双向队列就已经写完了，接下来就是要用它和HashMap组合完成一个LRU算法了。 // Remove 删除一个元素 func (list *LinkedList) Remove(element *Element) { next := element.Next pre := element.Pre next.Pre = pre pre.Next = next } // AddToHead 将一个元素加到队列头部 func (list *LinkedList) AddToHead(element *Element) { head := list.Head headNext := head.Next head.Next = element headNext.Pre = element element.Next = headNext element.Pre = head } ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:2:1","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"双向队列与HashMap组合实现LRU 首先定义一个Cache结构，包含最大容量值、当前容量值、一个双向队列和一个HashMap，HashMap的作用是通过key值在O(1)复杂度内获得对应的队列元素，我还添加了一个回调函数用于测试。 type Cache struct { maxCapacity int //最大容量 capacity int //当前容量 list *linkedlist.LinkedList cache map[string]*linkedlist.Element OnEvicted func(key string, value linkedlist.Data) //当一个element被删除时执行该方法 } 之后便是最重要的Get和Add方法。Get方法的实现思路就是根据key在HashMap中获得对应的队列元素，将元素移动到队首，然后返回元素中的数据。Add方法可以先调用Get方法判断该key值是否已经存在于队列中，如果已存在，Get方法已经将对应元素移至队首，只需更改对应的元素中的数据；如果不存在，则新建元素并加至队首。添加成功之后，还要判断LRU容量是否超出预设的最大值，若超出最大值，需要删除队尾元素直到容量小于等于预设的最大值。至此，LRU算法就已经完成。 func (c *Cache) Get(key string) (value linkedlist.Data, ok bool) { if element, ok := c.cache[key]; ok { list := c.list //删除element再将其加到队列头部 list.Remove(element) list.AddToHead(element) return element.Value, true } return linkedlist.Data{}, false } func (c *Cache) Add(key string, value linkedlist.Data) { if _, ok := c.Get(key); ok { c.cache[key].Value = value } else { element := linkedlist.Element{ Key: key, Value: value, } c.list.AddToHead(\u0026element) c.cache[key] = \u0026element c.capacity += element.Value.Length() //容量超过限度 for c.capacity \u003e c.maxCapacity { toRemove := c.list.Tail.Pre c.list.Remove(toRemove) delete(c.cache, toRemove.Key) c.capacity -= toRemove.Value.Length() //执行回调方法 if c.OnEvicted != nil { c.OnEvicted(toRemove.Key, toRemove.Value) } } } } ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:2:2","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"一致性哈希算法 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:3:0","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"多种方案 方案一：数组+排序 算出所有待加入的节点的Hash值放入一个数组中，然后使用排序算法将其从小到大进行排序。路由一个key时，算出其Hash值，只需要在数组中找到第一个Hash值比它大的节点就可以了。比如服务器节点的Hash值是 [0,2,4,6,8,10]，待路由的节点的Hash值是7，则只需要找到第一个比7大的整数，也就是8，就是我们要找的最终需要路由过去的服务器节点。 这种方案下，增删一个节点的时间复杂度为O(nlogn)，路由的复杂度为二分查找的O(logn)。这里要注意如果在线添加节点，因原数组已经有序，在加入一个元素后使用传统的快速排序效率很低。 方案二：遍历+List 由于排序比较消耗性能，那么可以选择不排序，采用直接遍历的方式。服务器节点的Hash值不排序，全部放到一个List中。当路由一个key时，算出其Hash值，遍历List，比待路由节点 Hash值大的算出差值并记录，比待路由节点Hash值小的忽略，算出所有的差值之后，最小的那个，就是最终需要路由过去的节点。 这种方案下，增删一个节点的时间复杂度为O(1)，路由的复杂度为O(n)。 方案三：红黑树 红黑树主要的作用是用于存储有序的数据，因此相当于省略了排序这步骤。在这个方案下，增删和查找的时间复杂度均为O(logn)。 ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:3:1","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["分布式系统"],"content":"具体实现 我选择的是带有虚拟节点的方案一，因为它最简单(狗头)。 首先定义一个Map结构，它就可以代表一个哈希环了。 type Map struct { hash Hash //Hash函数，我默认使用的是CRC32 replicas int //虚拟节点的倍数，代表每个真实节点对应几个虚拟节点 Keys []int //经过排序，存储所有节点的哈希值 hashMap map[int]string //虚拟节点和真实节点的映射，虚拟节点即为一个hash值，真实节点为一个地址 } 接下来的Get、Delete和Add方法均与上面方案一的描述相符，具体见代码与注释。 // Add 向Map中添加真实节点 func (m *Map) Add(addrs ...string) { for _, addr := range addrs { //添加虚拟节点 for i := 0; i \u003c m.replicas; i++ { hash := int(m.hash([]byte(strconv.Itoa(i) + addr))) //将节点的哈希值加入切片 m.Keys = append(m.Keys, hash) //将虚拟节点映射到真实节点地址 m.hashMap[hash] = addr } } sort.Ints(m.Keys) //使数组有序 } // Delete 从Map中删除元素 func (m *Map) Delete(addrs ...string) { for _, addr := range addrs { //删除虚拟节点 for i := 0; i \u003c m.replicas; i++ { hash := int(m.hash([]byte(strconv.Itoa(i) + addr))) //从切片中删除虚拟节点的哈希值 index := sort.SearchInts(m.Keys, hash) m.Keys = append(m.Keys[:index], m.Keys[index+1:]...) //删除map中的映射 delete(m.hashMap, hash) } } } // Get 根据key值来确定真实节点地址 func (m *Map) Get(key string) string { if len(m.Keys) == 0 { return \"\" } hash := int(m.hash([]byte(key))) //二分查找大于key的哈希值的最小虚拟节点哈希值 idx := sort.Search(len(m.Keys), func(i int) bool { return m.Keys[i] \u003e= hash }) //取模是因为key的hash可能大于所有节点的hash，这时应定位到第一个节点 return m.hashMap[m.Keys[idx%len(m.Keys)]] } ","date":"2021-12-30","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/:3:2","tags":["个人项目"],"title":"分布式缓存","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"categories":["OS"],"content":"操作系统概述","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":" 前几天看面经，看到个问题：“你如何理解操作系统？”，我很难找到一个好的切入点来分析，所以在这里整理一下对操作系统的理解，以加深记忆，形成大局观。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:0:0","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"操作系统的简单定义 操作系统（Operating System）是计算机系统中的一个基本程序集合，负责与硬件交互，并为用户程序提供执行环境。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:1:0","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"操作系统的作用 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:2:0","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"硬件资源的管理者 为了允许我们的计算机能够运行多个程序，就要解决各个程序间的资源分配和保护问题，既要为一个程序分配足够的内存、CPU运行时长等资源以让其正常运行，又要防止程序恶意争夺其他程序的资源。操作系统的作用之一便是管理这些硬件资源，让程序正确且高效地运行。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:2:1","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"封装底层硬件设备 在不同的计算机中，处理器架构各有差异，IO设备也各不相同，必然造成了对他们的使用方式也不尽相同，然而如果让每个人在写程序的时候都要考虑这种不同，未免太过繁琐。操作系统为了解决这个问题，提供了一系列接口（API），供用户程序调用，以运行程序、访问内存和设备，这些接口称作“系统调用（System Call）”。这其中就包括了虚拟文件系统提供的一系列用于文件操作的函数，如fopen()用于打开文件、write()用于写文件等等；还包括了fork()、clone()用于创建进程、线程的系统调用；还有如malloc()等用于内存操作的系统调用。 系统调用 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:2:2","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"虚拟化 操作系统主要利用一种通用技术，叫做“虚拟化（Virtualization）”,也就是说，操作系统将物理资源（如内存、处理器、磁盘）转换为更通用、更强大且更易于使用的虚拟形式。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:3:0","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"虚拟化CPU 将单个CPU转换为看似无限数量的CPU，从而让许多程序好像是在同时运行，这就是所谓的“虚拟化CPU”。操作系统为正在运行的程序提供了一种抽象，叫做“进程”，通过对进程的调度来实现了多个程序在单个CPU上的“同时”运行。为了知道当前到底该运行哪个进程、这个进程该运行多长时间，操作系统还提供了一些策略来进行进程调度，即“进程调度算法”。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:3:1","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"虚拟化内存 计算机提供的物理内存模型非常简单，就是一个字节数组，需要一个物理地址来进行内存访问。程序运行时会不断进行内存访问以操作它的运行时数据，如何保证多个程序可以高效、无冲突地访问内存中属于自己的数据，这就是虚拟化内存解决的问题。每个进程都有属于自己的虚拟地址空间，并通过虚拟地址进行内存访问，这给程序提供了一种独占所有物理内存的假象，操作系统会以某种方式将虚拟地址映射为物理地址，并管理各个进程的虚拟地址空间，保证一个进程的内存访问不会影响到其他进程。 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:3:2","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["OS"],"content":"持久性 在系统内存中，如果断电，其中保存的数据便会全部丢失，因此，我们需要磁盘来持久地存储数据。为此，操作系统提供了文件系统来管理磁盘，利用文件系统，用户可以高效地在磁盘上创建、删除文件，并保证其持久地存储。Linux中的文件操作会经历多个层次的处理，其主要结构如下图。 Linux块IO分层 ","date":"2021-12-03","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/:4:0","tags":null,"title":"操作系统概述","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"},{"categories":["数据结构与算法"],"content":"二叉树的常规遍历","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"先序遍历 ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:1:0","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"递归实现 class Solution { private List\u003cInteger\u003e ans; public List\u003cInteger\u003e preorderTraversal(TreeNode root) { ans = new ArrayList\u003c\u003e(); preOrderRecur(root); return ans; } private void preOrderRecur(TreeNode root){ if(root == null) return; ans.add(root.val); preOrderRecur(root.left); preOrderRecur(root.right); } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:1:1","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"非递归实现（栈） 先将root节点压如栈中，之后反复执行：从栈中弹出一个元素，计入遍历结果，将其右节点、左节点分别压入栈中。直到栈为空。 class Solution { public List\u003cInteger\u003e preorderTraversal(TreeNode root) { if(root == null) return new ArrayList\u003c\u003e(); List\u003cInteger\u003e ans = new ArrayList\u003c\u003e(); Stack\u003cTreeNode\u003e stack = new Stack\u003c\u003e(); stack.push(root); while(!stack.empty()){ root = stack.pop(); ans.add(root.val); if(root.right != null) stack.push(root.right); if(root.left != null) stack.push(root.left); } return ans; } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:1:2","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"中序遍历 ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:2:0","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"递归实现 class Solution { private List\u003cInteger\u003e ans; public List\u003cInteger\u003e inorderTraversal(TreeNode root) { ans = new ArrayList\u003c\u003e(); inOrderRecur(root); return ans; } private void inOrderRecur(TreeNode root){ if(root == null) return; inOrderRecur(root.left); ans.add(root.val); inOrderRecur(root.right); } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:2:1","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"非递归实现（栈） 申请一个新的栈，记为stack。初始时，令变量cur=root。 先把cur节点压入栈中，对以cur节点为头的整棵子树来说，依次把左边界压入栈中。即不停地令cur=cur.left，然后重复步骤2。 不断重复步骤2，直到发现cur为空，此时从stack中弹出一个节点，记为node。将node加入遍历结果，并让cur=node.right，然后重复步骤2。 当stack为空且cur为空时，遍历结束。 class Solution { public List\u003cInteger\u003e inorderTraversal(TreeNode root) { if(root == null) return new ArrayList\u003c\u003e(); List\u003cInteger\u003e ans = new ArrayList\u003cInteger\u003e(); Stack\u003cTreeNode\u003e stack = new Stack\u003c\u003e(); while(!stack.empty() || root != null){ if(root != null){ stack.push(root); root = root.left; }else{ root = stack.pop(); ans.add(root.val); root = root.right; } } return ans; } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:2:2","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"后序遍历 ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:3:0","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"递归实现 class Solution { private List\u003cInteger\u003e ans; public List\u003cInteger\u003e postorderTraversal(TreeNode root) { ans = new ArrayList\u003c\u003e(); posOrderRecur(root); return ans; } private void posOrderRecur(TreeNode root){ if(root == null) return; posOrderRecur(root.left); posOrderRecur(root.right); ans.add(root.val); } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:3:1","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"非递归实现（栈） 申请一个栈，记为s1，然后将根节点root压入s1中。 将s1中弹出的节点记为cur，将cur的左右孩子节点依次压入s1中。 在整个过程中，每个从s1弹出的节点，都将其压入s2中。 不断重复步骤2和步骤3，直到s1为空。 将s2中的所有节点弹出，其顺序即为后序遍历。 整体思想其实就是：进入s1中的顺序为“根-\u003e左-\u003e右”，出s1的顺序（即进入s2的顺序）为“根-\u003e右-\u003e左”，再用s2将其反转，便成了“左-\u003e右-\u003e根”。 class Solution { public List\u003cInteger\u003e postorderTraversal(TreeNode root) { if(root == null) return new ArrayList\u003c\u003e(); Stack\u003cTreeNode\u003e s1 = new Stack\u003c\u003e(); Stack\u003cTreeNode\u003e s2 = new Stack\u003c\u003e(); s1.push(root); while(!s1.empty()){ root = s1.pop(); s2.push(root); if(root.left != null) s1.push(root.left); if(root.right != null) s1.push(root.right); } List\u003cInteger\u003e ans = new ArrayList\u003c\u003e(); while(!s2.empty()){ ans.add(s2.pop().val); } return ans; } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:3:2","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"层序遍历 申请一个双端队列list，将根节点加入list中。变量last为当前遍历的层的最后一个节点，nLast为下一层的最后一个节点。队列row为当前层中的元素，当前层遍历结束后将其加入遍历结果ans中。 取list的第一个节点记为cur，将其值加入row中，再将其左右孩子节点依次加入list尾端，并维护nLast为下一层的最右节点。 当cur等于last时，表明该换行了，令last=nLast，将row加入ans中。 重复步骤2、3直到list为空。 class Solution { public List\u003cList\u003cInteger\u003e\u003e levelOrder(TreeNode root) { if(root == null) return new ArrayList\u003c\u003e(); List\u003cList\u003cInteger\u003e\u003e ans = new ArrayList\u003c\u003e(); LinkedList\u003cTreeNode\u003e list = new LinkedList\u003c\u003e(); List\u003cInteger\u003e row = new ArrayList\u003c\u003e(); list.addLast(root); TreeNode cur = null, last = root, nLast = null; while(!list.isEmpty()){ cur = list.pollFirst(); row.add(cur.val); if(cur.left != null){ list.addLast(cur.left); nLast = cur.left; } if(cur.right != null){ list.addLast(cur.right); nLast = cur.right; } if(cur == last){ ans.add(row); row = new ArrayList\u003c\u003e(); last = nLast; } } return ans; } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:4:0","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据结构与算法"],"content":"ZigZag遍历（锯齿形层序遍历） 类似于层序遍历，需添加一个变量记录当前层是从左至右遍历还是从右至左遍历，并且nLast维护方式改变，具体见代码。 class Solution { public List\u003cList\u003cInteger\u003e\u003e zigzagLevelOrder(TreeNode root) { if(root == null) return new ArrayList\u003c\u003e(); List\u003cList\u003cInteger\u003e\u003e ans = new ArrayList\u003c\u003e(); LinkedList\u003cTreeNode\u003e list = new LinkedList\u003c\u003e(); List\u003cInteger\u003e row = new ArrayList\u003c\u003e(); TreeNode last = root, nLast = null, cur = null; boolean ltor = true;//第一层为从左至右遍历 list.addLast(root); while(list.size() \u003e 0){ if(ltor){ cur = list.pollFirst(); row.add(cur.val); if(cur.left != null){ list.addLast(cur.left); if(nLast == null) nLast = cur.left; } if(cur.right != null){ list.addLast(cur.right); if(nLast == null) nLast = cur.right; } }else{ cur = list.pollLast(); row.add(cur.val); if(cur.right != null){ list.addFirst(cur.right); if(nLast == null) nLast = cur.right; } if(cur.left != null){ list.addFirst(cur.left); if(nLast == null) nLast = cur.left; } } if(cur == last){ last = nLast; nLast = null; ltor = !ltor;//下一层与当前层遍历顺序相反 ans.add(row); row = new ArrayList\u003c\u003e(); } } return ans; } } ","date":"2021-12-01","objectID":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/:5:0","tags":["树"],"title":"二叉树的常规遍历","uri":"/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B8%B8%E8%A7%84%E9%81%8D%E5%8E%86/"},{"categories":["数据库"],"content":"InnoDB中的锁","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"InnoDB有哪些锁？ ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:1:0","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"行锁 InnoDB存储引擎中有如下两种行锁： 共享锁(S Lock) 排他锁(X Lock) 其相互兼容性如下表所示： X S X 不兼容 不兼容 S 不兼容 兼容 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:1:1","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"意向锁 InnoDB存储引擎支持多粒度锁定，这种锁定允许事务在行级上的锁与表级上的锁同时存在。为了支持在不同粒度上的锁定，InnoDB引入了意向锁(Intention Lock)。意向锁将锁定对象分为多个层次，若希望在细粒度层次上加锁(行锁)，则需要先在粗粒度上加锁(意向锁)，可将意向锁理解为表级别的锁。 InnoDB中有两种意向锁： 意向共享锁(IS Lock) 意向排他锁(IX Lock) 其兼容性如下(表中的S和X为表级别的共享、排他锁)： IS IX S X IS 兼容 兼容 兼容 不兼容 IX 兼容 兼容 不兼容 不兼容 S 兼容 不兼容 兼容 不兼容 X 不兼容 不兼容 不兼容 不兼容 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:1:2","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"行锁 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:2:0","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"行锁算法 InnoDB中有三种行锁算法： Record Lock：单个行记录上的锁 Gap Lock：间隙锁，锁定一个范围，但是不包括行记录本身 Next-Key Lock：Gap Lock + Record Lock ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:2:1","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"解决幻像(Phantom Problem)问题 幻像问题(Phantom Problem)在MySQL官方文档中给出了定义：The so-called phantom problem occurs within a transaction when the same query produces different sets of rows at different times.。大致意思是：当同一条查询在不同的时间产生不同的结果集，所谓的Phantom Problem就会在事务中发生。例如事务A按照一定搜索条件进行数据读取，期间事务B插入(删除)或更改了相同搜索条件的数据，事务A再次按照原先条件进行读取时，发现与第一次读取的结果出现了不同，好像出现了幻觉(Phantom)。在很多书中又给出了两个名词，分别是幻读(Phantom Read)和不可重复读(Nonrepeatable Read)。解释为：不可重复读指事务B Update数据造成的问题，幻读指事务B Insert或Delete数据造成的问题，这两者的定义也均与维基百科中的一致。这里的“幻读”其实和官方文档中的幻行(Phantom Row)问题是一样的，在官方文档中有这句话：If a [SELECT] is executed twice, but returns a row the second time that was not returned the first time, the row is a “phantom” row。在解决了幻像问题的Repeatable Read级别下，使用Next-Key Lock：Gap Lock + Record Lock来锁定读取到的数据行及其检索范围。 这里注意，进行“一致性非锁定读”(快照读)时均使用“多版本并发控制(MVCC)”来避免幻像问题，在“一致性锁定读”(当前读)的情况下才会使用锁算法来避免此问题。 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:2:2","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"存储引擎层面进行的锁的优化 锁降级 当查询的索引具有唯一属性时，InnoDB会对Next-Key Lock进行优化，将其降级为Record Lock，即锁住索引本身，而不是范围。这里举个例子，首先创建表: CREATE TABLE t (a INT PRIMARY KEY); INSERT INTO t SELECT 1; INSERT INTO t SELECT 2; INSERT INTO t SELECT 5; 接下来执行表中的语句: 时间 会话A 会话B 1 BEGIN; 2 SELECT * FROM t WHERE a=5 FOR UPDATE; 3 BEGIN; 4 INSERT INTO t SELECT 4; 5 COMMIT; 6 COMMIT; 由于a是具有唯一属性的索引，在上面的例子中，会话B的COMMIT会直接成功，不需要阻塞。这种锁降级会大大提高数据库的并发性。如果查询的索引不具有唯一属性，则会对该索引加Next-Key Lock，但是对应的聚簇索引依旧为Record Lock。为了说明这一点，我们再创建一个表: CREATE TABLE z (a INT,b INT, PRIMARY KEY(a),KEY(b)); INSERT INTO z SELECT 1,1; INSERT INTO z SELECT 3,1; INSERT INTO z SELECT 5,3; INSERT INTO z SELECT 7,6; 接着执行下面的SQL语句: SELECT * FROM z WHERE b=3 FOR UPDATE; 此时则会对索引b加一个Next-key Lock，其范围是(1,6),对索引a加一个Record Lock，加在了a=5的记录上。因此，下面的SQL语句都会被阻塞： SELECT * FROM z WHERE a=5 LOCK IN SHARE MODE; INSERT INTO z SELECT 4,2; INSERT INTO z SELECT 6,5; 锁升级 维护锁信息是一个占用内存的操作，为了避免锁信息占用过多内存，在Microsoft SQL Server中有锁升级的策略，即在必要的时候将行锁升级为页锁，或将页锁升级为表锁。然而，InnoDB存储引擎不存在锁升级的情况，这得益于InnoDB采用位图的方式记录每个数据页的锁信息，占用内存极少。 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:2:3","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"意向锁有什么用 直接看例子：事务A锁住了表中的一行，让这一行只能读，不能写。之后，事务B申请整个表的写锁。如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。事务B申请表锁的时候，需要确认表中的所有行都没有被上锁，这时候如果没有意向锁，则需要遍历每一行，很费时间。如果事务A在加行锁前对表加上意向锁，事务B只需判断是否有意向锁来决定是否阻塞，效率明显提高。 总结一下就是：意向锁是一种快速判断表锁是否与之前可能存在的行锁冲突的机制。 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:3:0","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":["数据库"],"content":"解决死锁问题 死锁是指两个以上的事务在执行过程中，因争夺锁而造成的一种互相等待的现象。 解决死锁问题最简单的方法是超时机制，即两个事务互相等待时，当一个事务等待的时间超过了设置的阈值，便对其进行回滚，使另一个事务得以进行。参数innodb_lock_wait_timeout可以用来设置超时时间。这里就涉及到另外一个参数：innodb_rollback_on_timeout，该参数的决定了当前请求锁超时之后回滚的是整个事物还是仅当前语句，默认值是off，即回滚当前语句。 还有另一种方式便是等待图(wait-for graph)。在等待图中，事务为图中的节点，节点T1指向节点T2定义为：事务T1在等待事务T2占用的资源；或者是：事务T1与事务T2等待相同的资源，而事务T1发生在事务T2后面。可以想到，若图中存在回路，即可认为存在死锁，此时InnoDB会在回路中选择回滚量最小的事务进行回滚。innodb_deadlock_detect参数可以开启或关闭这种检测方法。 ","date":"2021-11-07","objectID":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/:4:0","tags":["MySQL"],"title":"InnoDB中的锁","uri":"/innodb%E4%B8%AD%E7%9A%84%E9%94%81/"},{"categories":null,"content":"西安电子科技大学2020级本科生 ","date":"0001-01-01","objectID":"/about/:0:1","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"爱好Distributed System、Database System ","date":"0001-01-01","objectID":"/about/:0:2","tags":null,"title":"关于我","uri":"/about/"}]